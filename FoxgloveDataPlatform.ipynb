{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bbce570-d518-4f7c-ac72-74d93b11bf32",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Analyzing and Visualizing Data from Foxglove Data Platform\n",
    "\n",
    "*NOTE: Corresponding [blog post here](https://foxglove.dev/blog).*\n",
    "\n",
    "**[Foxglove Data Platform](https://foxglove.dev/data-platform) is a scalable platform for organizing and managing your team's robotics data.** You can log in to [its web console interface](https://console.foxglove.dev) to upload data, tag events of interest, and query data for a given robot and time range, even if that data spans multiple recording sessions.\n",
    "\n",
    "In this notebook, **we'll demonstrate how to retrieve messages from Data Platform and process them for insightful visualizations.** We'll be using self-driving car data from the [nuScenes dataset](https://www.nuscenes.org/nuscenes), and writing Python code to visualize its route, IMU acceleration, and perceived objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8c52a6-5a3b-4be9-aed4-61539972e760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to install some dependencies\n",
    "\n",
    "!pip install --index-url https://rospypi.github.io/simple rosbag\n",
    "!pip install mcap-ros1-support foxglove-data-platform pandasql"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80dc1db1-d53f-4e54-a4c9-1e49afee96e7",
   "metadata": {},
   "source": [
    "## 2. Create a Foxglove Data Platform client\n",
    "\n",
    "Next, we'll create an instance of our Foxglove Data Platform client that we'll use to retrieve messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e093ce-ebab-4781-8e05-449d62b0380a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from foxglove_data_platform.client import Client\n",
    "\n",
    "# Read-only public key for demonstration purposes\n",
    "client = Client(token=\"fox_sk_CFlhbEgxMQbHBQGRCNE7c3CBaOxtrpk5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95dbd308-dec5-4d60-9678-def3f061ab05",
   "metadata": {},
   "source": [
    "## 3. View available data coverage\n",
    "\n",
    "*We'll be using the Python [`datetime`](https://docs.python.org/3/library/datetime.html) and [`pandas`](https://pandas.pydata.org/) modules for this step.*\n",
    "\n",
    "Lastly, we'll view the available data coverage in our Foxglove Data Platform account, to determine the devices and time ranges we need to query for the data we want to visualize.\n",
    "\n",
    "Let's limit the scope of our visualization to 2018 data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e24c79-0998-44b4-a82c-e385adb84c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "coverage = client.get_coverage(start=datetime(2018, 1, 1), end=datetime(2019,1,1))\n",
    "coverage = sorted(coverage, key=lambda c: c['start'])\n",
    "pd.DataFrame(coverage).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3f67c6-0c63-4680-82c1-665b65c0d44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's download some GPS messages.\n",
    "\n",
    "gps_messages = [\n",
    "    (message.latitude, message.longitude)\n",
    "    for topic, record, message in client.get_messages(\n",
    "        device_id=coverage[1][\"device_id\"],\n",
    "        start=coverage[1][\"start\"],\n",
    "        end=coverage[1][\"end\"],\n",
    "        topics=[\"/gps\"],\n",
    "    )\n",
    "]\n",
    "pd.DataFrame(gps_messages, columns=[\"lat\", \"lon\"]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a92070-d30b-4fe4-b919-077801eda318",
   "metadata": {},
   "source": [
    "Each row in the output above corresponds to every discrete recording available between January 1, 2018 and January 1, 2019.\n",
    "\n",
    "We see that there is only one device (i.e. robot) with 2018 data – we'll be using its ID (dev_vsXaJAH6X6oWDJrw) when querying its data in the next steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5331c811-20d0-401d-9293-8ba7921fa1a5",
   "metadata": {},
   "source": [
    "# Mapping the route\n",
    "\n",
    "To start exploring our self-driving data, let's see the route that our car took by plotting its GPS coordinates on a map.\n",
    "\n",
    "Now that we know the data available to us, we can fetch it using our Data Platform client's `get_messages` API call. \n",
    "\n",
    "Let's focus on one recording – specifically the ride that happened on August 1, 2018 (`coverage[1]`). We'll use a Python list comprehension to convert our messages into a list of tuples that we can easily insert into a `pandas` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3be150f-2d3f-4add-ac0a-b63a66694dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gps_messages = [\n",
    "    (message.latitude, message.longitude)\n",
    "    for topic, record, message in client.get_messages(\n",
    "        device_id=coverage[1][\"device_id\"],\n",
    "        start=coverage[1][\"start\"],\n",
    "        end=coverage[1][\"end\"],\n",
    "        topics=[\"/gps\"],\n",
    "    )\n",
    "]\n",
    "pd.DataFrame(gps_messages, columns=[\"lat\", \"lon\"]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da29017-422a-429a-9fcf-82b854e88bb1",
   "metadata": {},
   "source": [
    "We can use this same list of tuples to plot a list of locations on a [`folium`](https://python-visualization.github.io/folium/) map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acef9757-2d27-4394-9f85-d7221ec19089",
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "\n",
    "figure = folium.Figure(width=640, height=480)\n",
    "map = folium.Map(location=gps_messages[0], zoom_start=200, width=\"100%\")\n",
    "folium.PolyLine(\n",
    "    locations=gps_messages,\n",
    "    weight=10,\n",
    "    color=\"purple\",\n",
    ").add_to(map)\n",
    "map.add_to(figure)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c875d0-e357-4869-aace-43e80dcbbe4f",
   "metadata": {},
   "source": [
    "We can see that on August 1, 2018, our self-driving car navigated a stretch of Congress Street in Boston."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568c8fcd-a438-4e18-bb0f-7eee016797ed",
   "metadata": {},
   "source": [
    "# Plotting IMU acceleration\n",
    "\n",
    "For our first visualization, we focused on just one recorded drive. For this next one, let's fetch messages across multiple recording sessions to plot our robot's acceleration across all 2018 drives.\n",
    "\n",
    "We can take advantage of Data Platform's ability to fetch messages across multiple recording sessions by specifying the time range we want in our `get_messages` call. Once again, we'll use a list comprehension to convert our message objects into dictionaries that we can pull into a `pandas` dataframe and plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3242bf6-315c-4a8c-975e-a75480409bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "imu_messages = [\n",
    "    {\n",
    "        \"time\": pd.Timestamp(message.header.stamp.to_nsec(), unit=\"ns\").isoformat(),\n",
    "        \"accel_x\": message.linear_acceleration.x,\n",
    "        \"accel_y\": message.linear_acceleration.y,\n",
    "    }\n",
    "    for topic, record, message in client.get_messages(\n",
    "        device_id=coverage[0][\"device_id\"],\n",
    "        start=coverage[0][\"start\"],\n",
    "        end=coverage[-1][\"end\"],\n",
    "        topics=[\"/imu\"],\n",
    "    )\n",
    "]\n",
    "pd.DataFrame(imu_messages).plot(x=\"time\", figsize=(10, 6), rot=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb668e96-3104-4f44-b746-4e9a1573829d",
   "metadata": {},
   "source": [
    "From the output above, we can see how our robot's x and y acceleration fluctuated throughout its 2018 drives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36bcdb1-9f9d-45d4-8e74-0b4750db8f31",
   "metadata": {},
   "source": [
    "# Classifying perceived object markers\n",
    "\n",
    "Finally, let's classify the perceived object markers that our self-driving car published while on the road.\n",
    "\n",
    "Let's focus on one drive again this time – `coverage[1]` – and query its `/markers/annotations` topic messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15e8a08-2c39-4083-8b25-1d603c3bae9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "marker_messages = client.get_messages(\n",
    "    device_id=coverage[1][\"device_id\"],\n",
    "    start=coverage[1][\"start\"],\n",
    "    end=coverage[1][\"end\"],\n",
    "    topics=[\"/markers/annotations\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a798b618-50ce-42e5-bbc3-50b7853aead1",
   "metadata": {},
   "source": [
    "We'll use the markers' colors as the keys in a `color_to_classname` lookup dictionary. \n",
    "\n",
    "Use [`matplotlib`](https://matplotlib.org/) to convert numbers between 0 to 1 into hex color codes, and [`pandasql`](https://pypi.org/project/pandasql/) to count and group the markers by type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f209f0-93b7-4fe3-9d84-b7b2561bd666",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "from pandasql import sqldf\n",
    "\n",
    "color_to_classname = {\n",
    "    \"#000000\": \"noise\",\n",
    "    \"#468250\": \"animal\",\n",
    "    \"#0000e6\": \"human.pedestrian.adult\",\n",
    "    \"#87ceeb\": \"human.pedestrian.child\",\n",
    "    \"#f08080\": \"human.pedestrian.construction_worker\",\n",
    "    \"#db7093\": \"human.pedestrian.personal_mobility\",\n",
    "    \"#000080\": \"human.pedestrian.police_officer\",\n",
    "    \"#f08080\": \"human.pedestrian.stroller\",\n",
    "    \"#8a2be2\": \"human.pedestrian.wheelchair\",\n",
    "    \"#708090\": \"movable_object.barrier\",\n",
    "    \"#d2691e\": \"movable_object.debris\",\n",
    "    \"#696969\": \"movable_object.pushable_pullable\",\n",
    "    \"#2f4f4f\": \"movable_object.trafficcone\",\n",
    "    \"#bc8f8f\": \"static_object.bicycle_rack\",\n",
    "    \"#dc143c\": \"vehicle.bicycle\",\n",
    "    \"#ff7f50\": \"vehicle.bus.bendy\",\n",
    "    \"#ff4500\": \"vehicle.bus.rigid\",\n",
    "    \"#ff9e00\": \"vehicle.car\",\n",
    "    \"#e99646\": \"vehicle.construction\",\n",
    "    \"#ffd700\": \"vehicle.emergency.ambulance\",\n",
    "    \"#ffd700\": \"vehicle.emergency.police\",\n",
    "    \"#ff3d63\": \"vehicle.motorcycle\",\n",
    "    \"#ff8c00\": \"vehicle.trailer\",\n",
    "    \"#ff6347\": \"vehicle.truck\",\n",
    "    \"#00cfbf\": \"flat.driveable_surface\",\n",
    "    \"#af004b\": \"flat.other\",\n",
    "    \"#4b004b\": \"flat.sidewalk\",\n",
    "    \"#70b43c\": \"flat.terrain\",\n",
    "    \"#deb887\": \"static.manmade\",\n",
    "    \"#ffe4c4\": \"static.other\",\n",
    "    \"#00af00\": \"static.vegetation\",\n",
    "    \"#fff0f5\": \"vehicle.ego\",\n",
    "}\n",
    "\n",
    "flattened_markers = []\n",
    "for topic, record, message in marker_messages:\n",
    "    for marker in message.markers:\n",
    "        color = mpl.colors.to_hex([marker.color.r, marker.color.g, marker.color.b])\n",
    "        class_name = color_to_classname[color]\n",
    "        flattened_markers.append((marker.text, class_name))\n",
    "annotations = pd.DataFrame(flattened_markers, columns=[\"annotation_id\", \"class_name\"])\n",
    "\n",
    "pysqldf = lambda q: sqldf(q, globals())\n",
    "pysqldf(\n",
    "    \"SELECT class_name,COUNT(*) as count FROM annotations GROUP BY class_name ORDER BY count DESC\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc617f97-2f14-42af-8ce5-4d7fdd66a931",
   "metadata": {},
   "source": [
    "From the output above, we can see how many examples of each perceived object our self-driving car encountered (943 cars, 879 adult pedestrians, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be4d7b5-43f7-4cab-9120-3d788ee5c7da",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "We hope this demo illustrated some of the many ways [Foxglove Data Platform](https://foxglove.dev/data-platform) can help you explore, manipulate, and visualize your robotics data – even outside the [Foxglove Studio app](https://foxglove.dev/studio).\n",
    "\n",
    "Join the Foxglove [Slack community](https://foxglove.dev/slack) and follow [our blog](https://foxglove.dev/blog) for more ideas on how to integrate Data Platform into your robotics development workflows."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
