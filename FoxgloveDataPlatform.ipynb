{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bbce570-d518-4f7c-ac72-74d93b11bf32",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Analyzing and Visualizing Data from Foxglove Data Platform\n",
    "\n",
    "**[Foxglove Data Platform](https://foxglove.dev/data-platform) is a scalable platform for organizing and managing your team's robotics data.** You can log in to [its web console interface](https://console.foxglove.dev) to upload data, tag events of interest, and query data for a given robot and time range, even if that data spans multiple recording sessions.\n",
    "\n",
    "In this notebook, **we'll demonstrate how to retrieve messages from Data Platform and process them for insights.** We'll be using self-driving car data from the [nuScenes dataset](https://www.nuscenes.org/nuscenes), and writing Python code to visualize its route, IMU acceleration, and perceived objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8c52a6-5a3b-4be9-aed4-61539972e760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install some dependencies\n",
    "%pip install mcap-ros1-support==0.4.0 foxglove-data-platform==0.2.1 pandasql > /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614afff2",
   "metadata": {},
   "source": [
    "### Loading data\n",
    "\n",
    "The first step in our analysis is loading some data. We'll use the foxglove data platform client library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e093ce-ebab-4781-8e05-449d62b0380a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from foxglove_data_platform.client import Client\n",
    "\n",
    "# Read-only public key for demonstration purposes\n",
    "client = Client(token=\"fox_sk_1dbfnSNxWmtT4cV82YCMA3lbQE3hcE3E\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95dbd308-dec5-4d60-9678-def3f061ab05",
   "metadata": {},
   "source": [
    "To query for data, we need to know a device id and some time range. The get_coverage method shows us available devices and data for 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e24c79-0998-44b4-a82c-e385adb84c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "all_devices_coverage = client.get_coverage(start=datetime(2018, 1, 1), end=datetime(2019,1,1))\n",
    "all_devices_coverage = sorted(all_devices_coverage, key=lambda c: c['start'])\n",
    "pd.DataFrame(all_devices_coverage).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ba9caf",
   "metadata": {},
   "source": [
    "For this notebook we want to restrict our search to a single device. In this data platform organization, different devices record data using different message encodings. The Python client library handles message decoding for us, so we can use the same code to explore messages encoded in JSON, Protobuf, ROS1 and ROS2 (CDR)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4cea2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device_id = \"dev_fj7b6mZSD54rJO7v\"      # use this device ID to get ROS1-encoded messages.\n",
    "# device_id = \"dev_KphdijgpmmnnmYaH\"    # use this device ID to get ROS2 CDR-encoded messages.\n",
    "coverage = [r for r in all_devices_coverage if r[\"device_id\"] == device_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899b2f64",
   "metadata": {},
   "source": [
    "Fetch GPS messages for the first entry from our previous coverage request. We could fetch data across any start/end range and device.\n",
    "\n",
    "We limit our data to the `/gps` topic since that's all we need for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3f67c6-0c63-4680-82c1-665b65c0d44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gps_messages = [\n",
    "    (message.latitude, message.longitude)\n",
    "    for topic, record, message in client.get_messages(\n",
    "        device_id=device_id,\n",
    "        start=coverage[1][\"start\"],\n",
    "        end=coverage[1][\"end\"],\n",
    "        topics=[\"/gps\"],\n",
    "    )\n",
    "]\n",
    "pd.DataFrame(gps_messages, columns=[\"lat\", \"lon\"]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f014ada",
   "metadata": {},
   "source": [
    "We now know the basics to loading our data. Next, we can analyze the data using existing jupyter notebook tools and practices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5331c811-20d0-401d-9293-8ba7921fa1a5",
   "metadata": {},
   "source": [
    "### Mapping the route\n",
    "\n",
    "Let's see the route that our car took by plotting its GPS coordinates on a map.\n",
    "\n",
    "We'll load data from on August 1, 2018 (`coverage[1]`) and use list comprehension to convert our messages into a list of tuples that we can insert into a `pandas` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3be150f-2d3f-4add-ac0a-b63a66694dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gps_messages = [\n",
    "    (message.latitude, message.longitude)\n",
    "    for topic, record, message in client.get_messages(\n",
    "        device_id=device_id,\n",
    "        start=coverage[1][\"start\"],\n",
    "        end=coverage[1][\"end\"],\n",
    "        topics=[\"/gps\"],\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da29017-422a-429a-9fcf-82b854e88bb1",
   "metadata": {},
   "source": [
    "**TIP**: We recommend splitting your data fetching and processing into separate cells. This lets you iterate on your analysis without re-downloading the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acef9757-2d27-4394-9f85-d7221ec19089",
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "\n",
    "figure = folium.Figure(width=640, height=480)\n",
    "map = folium.Map(location=gps_messages[0], zoom_start=200, width=\"100%\")\n",
    "folium.PolyLine(\n",
    "    locations=gps_messages,\n",
    "    weight=10,\n",
    "    color=\"purple\",\n",
    ").add_to(map)\n",
    "map.add_to(figure)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c875d0-e357-4869-aace-43e80dcbbe4f",
   "metadata": {},
   "source": [
    "We can see that on August 1, 2018, our self-driving car navigated a stretch of Congress Street in Boston."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568c8fcd-a438-4e18-bb0f-7eee016797ed",
   "metadata": {},
   "source": [
    "### Plotting IMU acceleration\n",
    "\n",
    "For our first analysis, we focused on just one recorded drive. For this analysis, let's fetch messages across a longer time range to plot our robot's acceleration across all 2018 drives.\n",
    "\n",
    "We can take advantage of Data Platform's ability to fetch messages across multiple recording sessions by specifying the time range we want in our `get_messages` call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3242bf6-315c-4a8c-975e-a75480409bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "imu_messages = [\n",
    "    {\n",
    "        \"time\": pd.Timestamp(message.header.stamp.to_nsec(), unit=\"ns\").isoformat(),\n",
    "        \"accel_x\": message.linear_acceleration.x,\n",
    "        \"accel_y\": message.linear_acceleration.y,\n",
    "    }\n",
    "    for topic, record, message in client.get_messages(\n",
    "        device_id=device_id,\n",
    "        start=coverage[0][\"start\"],\n",
    "        end=coverage[-1][\"end\"],\n",
    "        topics=[\"/imu\"],\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304827d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(imu_messages).plot(x=\"time\", figsize=(10, 6), rot=45);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb668e96-3104-4f44-b746-4e9a1573829d",
   "metadata": {},
   "source": [
    "From the output above, we can see how our robot's x and y acceleration fluctuated throughout its 2018 drives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36bcdb1-9f9d-45d4-8e74-0b4750db8f31",
   "metadata": {},
   "source": [
    "### Classifying perceived object markers\n",
    "\n",
    "Finally, let's classify the perceived object markers that our self-driving car published while on the road.\n",
    "\n",
    "We'll again use one specific time range – `coverage[1]` – and query its `/markers/annotations` topic messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15e8a08-2c39-4083-8b25-1d603c3bae9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "marker_messages = client.get_messages(\n",
    "    device_id=device_id,\n",
    "    start=coverage[1][\"start\"],\n",
    "    end=coverage[1][\"end\"],\n",
    "    topics=[\"/markers/annotations\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a798b618-50ce-42e5-bbc3-50b7853aead1",
   "metadata": {},
   "source": [
    "In our dataset, each marker color coorresponds to a specific _classification_. We'll use the marker color to lookup the classification and group markers by classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f209f0-93b7-4fe3-9d84-b7b2561bd666",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "from pandasql import sqldf\n",
    "\n",
    "color_to_classname = {\n",
    "    \"#000000\": \"noise\",\n",
    "    \"#468250\": \"animal\",\n",
    "    \"#0000e6\": \"human.pedestrian.adult\",\n",
    "    \"#87ceeb\": \"human.pedestrian.child\",\n",
    "    \"#f08080\": \"human.pedestrian.construction_worker\",\n",
    "    \"#db7093\": \"human.pedestrian.personal_mobility\",\n",
    "    \"#000080\": \"human.pedestrian.police_officer\",\n",
    "    \"#f08080\": \"human.pedestrian.stroller\",\n",
    "    \"#8a2be2\": \"human.pedestrian.wheelchair\",\n",
    "    \"#708090\": \"movable_object.barrier\",\n",
    "    \"#d2691e\": \"movable_object.debris\",\n",
    "    \"#696969\": \"movable_object.pushable_pullable\",\n",
    "    \"#2f4f4f\": \"movable_object.trafficcone\",\n",
    "    \"#bc8f8f\": \"static_object.bicycle_rack\",\n",
    "    \"#dc143c\": \"vehicle.bicycle\",\n",
    "    \"#ff7f50\": \"vehicle.bus.bendy\",\n",
    "    \"#ff4500\": \"vehicle.bus.rigid\",\n",
    "    \"#ff9e00\": \"vehicle.car\",\n",
    "    \"#e99646\": \"vehicle.construction\",\n",
    "    \"#ffd700\": \"vehicle.emergency.ambulance\",\n",
    "    \"#ffd700\": \"vehicle.emergency.police\",\n",
    "    \"#ff3d63\": \"vehicle.motorcycle\",\n",
    "    \"#ff8c00\": \"vehicle.trailer\",\n",
    "    \"#ff6347\": \"vehicle.truck\",\n",
    "    \"#00cfbf\": \"flat.driveable_surface\",\n",
    "    \"#af004b\": \"flat.other\",\n",
    "    \"#4b004b\": \"flat.sidewalk\",\n",
    "    \"#70b43c\": \"flat.terrain\",\n",
    "    \"#deb887\": \"static.manmade\",\n",
    "    \"#ffe4c4\": \"static.other\",\n",
    "    \"#00af00\": \"static.vegetation\",\n",
    "    \"#fff0f5\": \"vehicle.ego\",\n",
    "}\n",
    "\n",
    "flattened_markers = []\n",
    "for topic, record, message in marker_messages:\n",
    "    for marker in message.markers:\n",
    "        color = mpl.colors.to_hex([marker.color.r, marker.color.g, marker.color.b])\n",
    "        class_name = color_to_classname[color]\n",
    "        flattened_markers.append((marker.text, class_name))\n",
    "annotations = pd.DataFrame(flattened_markers, columns=[\"annotation_id\", \"class_name\"])\n",
    "\n",
    "pysqldf = lambda q: sqldf(q, globals())\n",
    "res = pysqldf(\n",
    "    \"SELECT class_name,COUNT(*) as count FROM annotations GROUP BY class_name ORDER BY count DESC\"\n",
    ")\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236983d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.plot.bar(x=\"class_name\", y=\"count\", legend=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc617f97-2f14-42af-8ce5-4d7fdd66a931",
   "metadata": {},
   "source": [
    "We can see how many examples of each perceived object our self-driving car encountered (943 cars, 879 adult pedestrians, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be4d7b5-43f7-4cab-9120-3d788ee5c7da",
   "metadata": {},
   "source": [
    "### End\n",
    "\n",
    "This demo illustrated some of the many ways you can analyze your robotics data wit Jupyter notebooks and [Foxglove Data Platform](https://foxglove.dev/data-platform).\n",
    "\n",
    "Signup and analyze your data at https://console.foxglove.dev/signin\n",
    "\n",
    "Join the Foxglove [Slack community](https://foxglove.dev/slack) and follow [our blog](https://foxglove.dev/blog) for more ideas on how to integrate Data Platform into your robotics development workflows."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
